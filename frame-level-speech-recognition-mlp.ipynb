{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9ERgBpbcMmB"
   },
   "source": [
    "# Frame-Level Speech Recognition with Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLkH6GMGcWcE"
   },
   "source": [
    "In this project, we will be working with MFCC data consisting of 28 features at each time step/frame. The model will be used to recognize the phoneme occured in that frame. After completion it will be submitted to the [\"11785 HW1P2 Fall 2024\" competition\"](https://www.kaggle.com/competitions/11785-hw1p2-f24/overview).\n",
    "\n",
    "\n",
    "\n",
    "This project was completed according to the first homework in Carnegie Mellon University's CMU 11-785: Deep Learning course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4vZbDmJvMp1"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T11:59:14.598008Z",
     "iopub.status.busy": "2025-01-21T11:59:14.597706Z",
     "iopub.status.idle": "2025-01-21T11:59:18.991740Z",
     "shell.execute_reply": "2025-01-21T11:59:18.990552Z",
     "shell.execute_reply.started": "2025-01-21T11:59:14.597984Z"
    },
    "id": "rwYu9sSUnSho",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install torchsummaryX==1.1.0 wandb --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-01-21T11:59:18.993511Z",
     "iopub.status.busy": "2025-01-21T11:59:18.993146Z",
     "iopub.status.idle": "2025-01-21T11:59:24.860032Z",
     "shell.execute_reply": "2025-01-21T11:59:24.859278Z",
     "shell.execute_reply.started": "2025-01-21T11:59:18.993480Z"
    },
    "id": "qI4qfx7tiBZt",
    "outputId": "ef79a3fc-5689-4e5a-d896-329b8a9d6a5c",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchsummaryX import summary\n",
    "import sklearn\n",
    "import gc\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import datetime\n",
    "import wandb\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T11:59:24.862004Z",
     "iopub.status.busy": "2025-01-21T11:59:24.861794Z",
     "iopub.status.idle": "2025-01-21T11:59:24.866082Z",
     "shell.execute_reply": "2025-01-21T11:59:24.865270Z",
     "shell.execute_reply.started": "2025-01-21T11:59:24.861986Z"
    },
    "id": "N-9qE20hmCgQ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### PHONEME LIST\n",
    "PHONEMES = [\n",
    "            '[SIL]',   'AA',    'AE',    'AH',    'AO',    'AW',    'AY',\n",
    "            'B',     'CH',    'D',     'DH',    'EH',    'ER',    'EY',\n",
    "            'F',     'G',     'HH',    'IH',    'IY',    'JH',    'K',\n",
    "            'L',     'M',     'N',     'NG',    'OW',    'OY',    'P',\n",
    "            'R',     'S',     'SH',    'T',     'TH',    'UH',    'UW',\n",
    "            'V',     'W',     'Y',     'Z',     'ZH',    '[SOS]', '[EOS]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T12:23:57.366280Z",
     "iopub.status.busy": "2025-01-21T12:23:57.365971Z",
     "iopub.status.idle": "2025-01-21T12:23:57.622219Z",
     "shell.execute_reply": "2025-01-21T12:23:57.621498Z",
     "shell.execute_reply.started": "2025-01-21T12:23:57.366256Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmobin-roohi\u001b[0m (\u001b[33mmobin-roohi-university-of-tehran\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"a35a4beb5d7e2e112211e9cd7e103b10585e3132\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vuzce0_TdcaR"
   },
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T12:24:02.130768Z",
     "iopub.status.busy": "2025-01-21T12:24:02.130481Z",
     "iopub.status.idle": "2025-01-21T12:24:02.141467Z",
     "shell.execute_reply": "2025-01-21T12:24:02.140449Z",
     "shell.execute_reply.started": "2025-01-21T12:24:02.130747Z"
    },
    "id": "YpLCvi3AJC5z",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset class to load train and validation data\n",
    "\n",
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root, phonemes = PHONEMES, context=0, partition= \"train-clean-100\"): \n",
    "        self.context = context\n",
    "        self.phonemes = phonemes\n",
    "\n",
    "        # MFCC directory\n",
    "        self.mfcc_dir = os.path.join(root, partition, 'mfcc')\n",
    "        \n",
    "        # Transcripts directory\n",
    "        self.transcript_dir = os.path.join(root, partition, 'transcript')\n",
    "\n",
    "        # List of MFCC and transcript files\n",
    "        mfcc_names = sorted(os.listdir(self.mfcc_dir))\n",
    "        transcript_names = sorted(os.listdir(self.transcript_dir))\n",
    "        assert len(mfcc_names) == len(transcript_names)\n",
    "\n",
    "        self.mfccs, self.transcripts = [], []\n",
    "\n",
    "        for i in range(len(mfcc_names)):\n",
    "            if i % 1000 == 0: \n",
    "                print(f\"Data {i} / {len(mfcc_names)}\")\n",
    "            # Load a single mfcc\n",
    "            mfcc = np.load(os.path.join(self.mfcc_dir, mfcc_names[i]))\n",
    "    \n",
    "            # Cepstral normalization\n",
    "            mfcc_norm = self.cepstral_normalization(mfcc)\n",
    "                    \n",
    "            # Load the corresponding transcript and removing [SOS] and [EOS]\n",
    "            transcript = np.load(os.path.join(self.transcript_dir, transcript_names[i]))[1:-1]\n",
    "            \n",
    "            # Save the preprocessed MFFCs and transcripts\n",
    "            self.mfccs.append(mfcc_norm)\n",
    "            self.transcripts.append(transcript)\n",
    "\n",
    "        # Concatenate all mfccs \n",
    "        self.mfccs = np.vstack(self.mfccs)\n",
    "\n",
    "        # Concatenate all transcripts \n",
    "        self.transcripts = np.concatenate(self.transcripts, axis=0)\n",
    "\n",
    "        # Length of the dataset is now the length of concatenated mfccs/transcripts\n",
    "        self.length = len(self.mfccs)\n",
    "\n",
    "        # We can introduce context by padding zeros on top and bottom of self.mfcc\n",
    "        zero_padding = np.zeros((self.context, 28))\n",
    "        self.mfccs = np.vstack([zero_padding, self.mfccs, zero_padding])\n",
    "\n",
    "        # Map transcripts to id integers using phonemes list\n",
    "        encoding_dict = {string : idx for idx, string in enumerate(phonemes)}\n",
    "        self.transcripts = np.array([encoding_dict[t] for t in self.transcripts])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        # Frame with context frames to the left, and right\n",
    "        frames = self.mfccs[ind : ind + 2 * self.context + 1, :]\n",
    "        \n",
    "        # After slicing, the array has a of shape 2*context+1 x 28. But MLP requires 1d data and not 2d.\n",
    "        frames = frames.flatten()\n",
    "\n",
    "        # Convert to tensors\n",
    "        frames = torch.FloatTensor(frames)\n",
    "        phonemes = torch.tensor(self.transcripts[ind])\n",
    "\n",
    "        return frames, phonemes\n",
    "\n",
    "    def cepstral_normalization(self, mfcc):\n",
    "        # Mean and standard deviation\n",
    "        mean = np.mean(mfcc, axis = 0)\n",
    "        std = np.std(mfcc, axis = 0) + 1e-8\n",
    "\n",
    "        # Normalize\n",
    "        mfcc_norm = (mfcc - mean) / std\n",
    "\n",
    "        return mfcc_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T12:24:03.586148Z",
     "iopub.status.busy": "2025-01-21T12:24:03.585865Z",
     "iopub.status.idle": "2025-01-21T12:24:03.593345Z",
     "shell.execute_reply": "2025-01-21T12:24:03.592469Z",
     "shell.execute_reply.started": "2025-01-21T12:24:03.586124Z"
    },
    "id": "e8KfVP39S6o7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset class to load test data (without transcripts)\n",
    "\n",
    "class AudioTestDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root, phonemes = PHONEMES, context=0, partition= \"test-clean\"): \n",
    "        self.context = context\n",
    "        self.phonemes = phonemes\n",
    "\n",
    "        # MFCC directory\n",
    "        self.mfcc_dir = os.path.join(root, partition, 'mfcc')\n",
    "\n",
    "        # List of MFCC files\n",
    "        mfcc_names = sorted(os.listdir(self.mfcc_dir))\n",
    "\n",
    "        self.mfccs = []\n",
    "\n",
    "        for i in range(len(mfcc_names)):\n",
    "            # Load a single mfcc\n",
    "            mfcc = np.load(os.path.join(self.mfcc_dir, mfcc_names[i]))\n",
    "    \n",
    "            # Cepstral normalization\n",
    "            mfcc_norm = self.cepstral_normalization(mfcc)\n",
    "            \n",
    "            # Save the preprocessed MFFCs\n",
    "            self.mfccs.append(mfcc_norm)\n",
    "\n",
    "        # Concatenate all mfccs \n",
    "        self.mfccs = np.vstack(self.mfccs)\n",
    "\n",
    "        # Length of the dataset is now the length of concatenated mfccs\n",
    "        self.length = len(self.mfccs)\n",
    "\n",
    "        # We can introduce context by padding zeros on top and bottom of self.mfcc\n",
    "        zero_padding = np.zeros((self.context, 28))\n",
    "        self.mfccs = np.vstack([zero_padding, self.mfccs, zero_padding])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        # Frame with context frames to the left, and right\n",
    "        frames = self.mfccs[ind : ind + 2 * self.context + 1, :]\n",
    "        \n",
    "        # After slicing, the array has a of shape 2*context+1 x 28. But MLP requires 1d data and not 2d.\n",
    "        frames = frames.flatten()\n",
    "\n",
    "        # Convert to tensors\n",
    "        frames = torch.FloatTensor(frames)\n",
    "\n",
    "        return frames\n",
    "\n",
    "    def cepstral_normalization(self, mfcc):\n",
    "        # Mean and standard deviation\n",
    "        mean = np.mean(mfcc, axis = 0)\n",
    "        std = np.std(mfcc, axis = 0) + 1e-8\n",
    "\n",
    "        # Normalize\n",
    "        mfcc_norm = (mfcc - mean) / std\n",
    "\n",
    "        return mfcc_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNacQ8bpt9nw"
   },
   "source": [
    "# Parameters Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WE7tsinAuLNy"
   },
   "source": [
    "We store the parameters and hyperparameters in a single configuration dictionary to make it easier to keep track of them during each experiment. It can also be used with weights and biases to log the parameters for each experiment and keep track of them across multiple experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T12:24:05.474551Z",
     "iopub.status.busy": "2025-01-21T12:24:05.474182Z",
     "iopub.status.idle": "2025-01-21T12:24:05.478538Z",
     "shell.execute_reply": "2025-01-21T12:24:05.477489Z",
     "shell.execute_reply.started": "2025-01-21T12:24:05.474521Z"
    },
    "id": "PmKwlFqgt_Zq",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'epochs'        : 5,\n",
    "    'batch_size'    : 1024,\n",
    "    'context'       : 40,\n",
    "    'init_lr'       : 1e-3,\n",
    "    'architecture'  : 'initial-stage',\n",
    "    'gamma'         : 0.5\n",
    "    # Add more as needed - e.g dropout values, weight decay, scheduler parameters\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mlwaKlDt_2c"
   },
   "source": [
    "# Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T12:24:07.258589Z",
     "iopub.status.busy": "2025-01-21T12:24:07.258281Z",
     "iopub.status.idle": "2025-01-21T12:34:23.023202Z",
     "shell.execute_reply": "2025-01-21T12:34:23.022491Z",
     "shell.execute_reply.started": "2025-01-21T12:24:07.258566Z"
    },
    "id": "7xi7V8x8W9z4",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data 0 / 28539\n",
      "Data 1000 / 28539\n",
      "Data 2000 / 28539\n",
      "Data 3000 / 28539\n",
      "Data 4000 / 28539\n",
      "Data 5000 / 28539\n",
      "Data 6000 / 28539\n",
      "Data 7000 / 28539\n",
      "Data 8000 / 28539\n",
      "Data 9000 / 28539\n",
      "Data 10000 / 28539\n",
      "Data 11000 / 28539\n",
      "Data 12000 / 28539\n",
      "Data 13000 / 28539\n",
      "Data 14000 / 28539\n",
      "Data 15000 / 28539\n",
      "Data 16000 / 28539\n",
      "Data 17000 / 28539\n",
      "Data 18000 / 28539\n",
      "Data 19000 / 28539\n",
      "Data 20000 / 28539\n",
      "Data 21000 / 28539\n",
      "Data 22000 / 28539\n",
      "Data 23000 / 28539\n",
      "Data 24000 / 28539\n",
      "Data 25000 / 28539\n",
      "Data 26000 / 28539\n",
      "Data 27000 / 28539\n",
      "Data 28000 / 28539\n",
      "Data 0 / 2703\n",
      "Data 1000 / 2703\n",
      "Data 2000 / 2703\n"
     ]
    }
   ],
   "source": [
    "# Train/validation data\n",
    "train_data = AudioDataset(\"/kaggle/input/11785-hw1p2-f24/11785-f24-hw1p2\", phonemes = PHONEMES, context=config[\"context\"], partition=\"train-clean-100\")\n",
    "val_data = AudioDataset(\"/kaggle/input/11785-hw1p2-f24/11785-f24-hw1p2\", phonemes = PHONEMES, context=config[\"context\"], partition=\"dev-clean\")\n",
    "\n",
    "# Test data\n",
    "test_data = AudioTestDataset(\"/kaggle/input/11785-hw1p2-f24/11785-f24-hw1p2\", phonemes = PHONEMES, context=config[\"context\"], partition=\"test-clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T12:38:29.316978Z",
     "iopub.status.busy": "2025-01-21T12:38:29.316645Z",
     "iopub.status.idle": "2025-01-21T12:38:29.325911Z",
     "shell.execute_reply": "2025-01-21T12:38:29.325064Z",
     "shell.execute_reply.started": "2025-01-21T12:38:29.316953Z"
    },
    "id": "4mzoYfTKu14s",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size     :  1024\n",
      "Context        :  40\n",
      "Input size     :  2268\n",
      "Output symbols :  42\n",
      "Train dataset samples = 36091157, batches = 35246\n",
      "Validation dataset samples = 1928204, batches = 1884\n",
      "Test dataset samples = 1934138, batches = 1889\n"
     ]
    }
   ],
   "source": [
    "# Dataloaders for train, val and test datasets\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = train_data,\n",
    "    num_workers = 4,\n",
    "    batch_size  = config['batch_size'],\n",
    "    pin_memory  = True,\n",
    "    shuffle     = True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = val_data,\n",
    "    num_workers = 2,\n",
    "    batch_size  = config['batch_size'],\n",
    "    pin_memory  = True,\n",
    "    shuffle     = False\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = test_data,\n",
    "    num_workers = 2,\n",
    "    batch_size  = config['batch_size'],\n",
    "    pin_memory  = True,\n",
    "    shuffle     = False\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Batch size     : \", config['batch_size'])\n",
    "print(\"Context        : \", config['context'])\n",
    "print(\"Input size     : \", (2*config['context']+1)*28)\n",
    "print(\"Output symbols : \", len(PHONEMES))\n",
    "\n",
    "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
    "print(\"Validation dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
    "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T12:38:31.899469Z",
     "iopub.status.busy": "2025-01-21T12:38:31.899152Z",
     "iopub.status.idle": "2025-01-21T12:38:37.733122Z",
     "shell.execute_reply": "2025-01-21T12:38:37.732036Z",
     "shell.execute_reply.started": "2025-01-21T12:38:31.899444Z"
    },
    "id": "n-GV3UvgLSoF",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 2268]) torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "# Testing code to check if the data loaders are working\n",
    "for i, data in enumerate(train_loader):\n",
    "    frames, phoneme = data\n",
    "    print(frames.shape, phoneme.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nxjwve20JRJ2"
   },
   "source": [
    "# Network Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NJzT-mRw6iy"
   },
   "source": [
    "This section defines the network architecture for the homework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T12:38:40.168282Z",
     "iopub.status.busy": "2025-01-21T12:38:40.167948Z",
     "iopub.status.idle": "2025-01-21T12:38:40.173906Z",
     "shell.execute_reply": "2025-01-21T12:38:40.173006Z",
     "shell.execute_reply.started": "2025-01-21T12:38:40.168250Z"
    },
    "id": "OvcpontXQq9j",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            # torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            # torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(128, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HejoSXe3vMVU"
   },
   "source": [
    "# Define Model, Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAhGBH7-xxth"
   },
   "source": [
    "Here we define the model, loss function, optimizer and optionally a learning rate scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T12:38:41.923852Z",
     "iopub.status.busy": "2025-01-21T12:38:41.923556Z",
     "iopub.status.idle": "2025-01-21T12:38:42.131788Z",
     "shell.execute_reply": "2025-01-21T12:38:42.131058Z",
     "shell.execute_reply.started": "2025-01-21T12:38:41.923830Z"
    },
    "id": "_qtrEM1ZvLje",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Layer                   Kernel Shape         Output Shape         # Params (K)      # Mult-Adds (M)\n",
      "====================================================================================================\n",
      "0_Linear                [2268, 1024]         [1024, 1024]             2,323.46                 2.32\n",
      "1_ReLU                             -         [1024, 1024]                    -                    -\n",
      "2_Linear                 [1024, 512]          [1024, 512]               524.80                 0.52\n",
      "3_ReLU                             -          [1024, 512]                    -                    -\n",
      "4_Linear                  [512, 256]          [1024, 256]               131.33                 0.13\n",
      "5_ReLU                             -          [1024, 256]                    -                    -\n",
      "6_Dropout                          -          [1024, 256]                    -                    -\n",
      "7_Linear                  [256, 128]          [1024, 128]                32.90                 0.03\n",
      "8_ReLU                             -          [1024, 128]                    -                    -\n",
      "9_Dropout                          -          [1024, 128]                    -                    -\n",
      "10_Linear                  [128, 42]           [1024, 42]                 5.42                 0.01\n",
      "====================================================================================================\n",
      "# Params:    3,017.90K\n",
      "# Mult-Adds: 3.02M\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE  = (2*config['context'] + 1) * 28 \n",
    "print(INPUT_SIZE)\n",
    "model       = Network(INPUT_SIZE, len(train_data.phonemes)).to(device)\n",
    "summary(model, frames.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T12:38:44.013259Z",
     "iopub.status.busy": "2025-01-21T12:38:44.012937Z",
     "iopub.status.idle": "2025-01-21T12:38:45.765838Z",
     "shell.execute_reply": "2025-01-21T12:38:45.765127Z",
     "shell.execute_reply.started": "2025-01-21T12:38:44.013233Z"
    },
    "id": "UROGEVJevKD-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Defining Loss function.\n",
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "\n",
    "# Defining Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= config['init_lr']) \n",
    "\n",
    "# Defining Scheduler for Learning Rate\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = config['gamma'])\n",
    "\n",
    "# # Later: Mixed Precision Training\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBwunYpyugFg"
   },
   "source": [
    "# Training and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T12:38:49.427262Z",
     "iopub.status.busy": "2025-01-21T12:38:49.426960Z",
     "iopub.status.idle": "2025-01-21T12:38:49.605863Z",
     "shell.execute_reply": "2025-01-21T12:38:49.605125Z",
     "shell.execute_reply.started": "2025-01-21T12:38:49.427238Z"
    },
    "id": "XblOHEVtKab2",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T12:38:51.076120Z",
     "iopub.status.busy": "2025-01-21T12:38:51.075800Z",
     "iopub.status.idle": "2025-01-21T12:38:51.083473Z",
     "shell.execute_reply": "2025-01-21T12:38:51.082676Z",
     "shell.execute_reply.started": "2025-01-21T12:38:51.076085Z"
    },
    "id": "8wjPz7DHqKcL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, dataloader, optimizer, criterion, update_interval=100):\n",
    "    model.train()\n",
    "    tloss, tacc = 0, 0  # Monitoring loss and accuracy\n",
    "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
    "\n",
    "    # Create a GradScaler once at the beginning of training.\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    for i, (frames, phonemes) in enumerate(dataloader):\n",
    "        ### Initialize Gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ### Move Data to Device (Ideally GPU)\n",
    "        frames = frames.to(device)\n",
    "        phonemes = phonemes.to(device)\n",
    "\n",
    "        ### Forward Propagation\n",
    "        ### Runs the forward pass with autocasting.\n",
    "        with autocast(device_type=device, dtype=torch.float16):\n",
    "            logits = model(frames)\n",
    "\n",
    "            ### Loss Calculation\n",
    "            loss = criterion(logits, phonemes)\n",
    "\n",
    "        ### Backward Propagation\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        tloss += loss.item()\n",
    "        tacc += torch.sum(torch.argmax(logits, dim=1) == phonemes).item() / logits.shape[0]\n",
    "\n",
    "        # Update progress bar less frequently\n",
    "        if (i + 1) % update_interval == 0 or (i + 1) == len(dataloader):\n",
    "            batch_bar.set_postfix(\n",
    "                loss=\"{:.04f}\".format(float(tloss / (i + 1))),\n",
    "                acc=\"{:.04f}%\".format(float(tacc * 100 / (i + 1)))\n",
    "            )\n",
    "            batch_bar.update(update_interval)\n",
    "\n",
    "        ### Release memory\n",
    "        del frames, phonemes, logits\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    batch_bar.close()\n",
    "    tloss /= len(dataloader)\n",
    "    tacc /= len(dataloader)\n",
    "\n",
    "    return tloss, tacc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T12:38:52.661729Z",
     "iopub.status.busy": "2025-01-21T12:38:52.661385Z",
     "iopub.status.idle": "2025-01-21T12:38:52.668260Z",
     "shell.execute_reply": "2025-01-21T12:38:52.667435Z",
     "shell.execute_reply.started": "2025-01-21T12:38:52.661706Z"
    },
    "id": "Q5npQNFH315V",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def eval(model, dataloader, update_interval=100):\n",
    "\n",
    "    model.eval() # set model in evaluation mode\n",
    "    vloss, vacc = 0, 0 # Monitoring loss and accuracy\n",
    "    batch_bar   = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
    "\n",
    "    for i, (frames, phonemes) in enumerate(dataloader):\n",
    "\n",
    "        ### Move data to device (ideally GPU)\n",
    "        frames      = frames.to(device)\n",
    "        phonemes    = phonemes.to(device)\n",
    "\n",
    "        # makes sure that there are no gradients computed as we are not training the model now\n",
    "        with torch.inference_mode():\n",
    "            ### Forward Propagation\n",
    "            logits  = model(frames)\n",
    "            ### Loss Calculation\n",
    "            loss    = criterion(logits, phonemes)\n",
    "\n",
    "        vloss   += loss.item()\n",
    "        vacc    += torch.sum(torch.argmax(logits, dim= 1) == phonemes).item()/logits.shape[0]\n",
    "\n",
    "        # Update progress bar less frequently\n",
    "        if (i + 1) % update_interval == 0 or (i + 1) == len(dataloader):\n",
    "            batch_bar.set_postfix(\n",
    "                loss=\"{:.04f}\".format(float(vloss / (i + 1))),\n",
    "                acc=\"{:.04f}%\".format(float(vacc * 100 / (i + 1)))\n",
    "            )\n",
    "            batch_bar.update(update_interval)\n",
    "\n",
    "        ### Release memory\n",
    "        del frames, phonemes, logits\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    batch_bar.close()\n",
    "    vloss   /= len(val_loader)\n",
    "    vacc    /= len(val_loader)\n",
    "\n",
    "    return vloss, vacc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMd_XxPku5qp"
   },
   "source": [
    "# Weights and Biases Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T12:38:54.444868Z",
     "iopub.status.busy": "2025-01-21T12:38:54.444539Z",
     "iopub.status.idle": "2025-01-21T12:38:54.448426Z",
     "shell.execute_reply": "2025-01-21T12:38:54.447507Z",
     "shell.execute_reply.started": "2025-01-21T12:38:54.444843Z"
    },
    "id": "SCDYx5VEu6qI",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# wandb.login(key=input(\"Please enter your wandb API key: \")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T12:39:59.058195Z",
     "iopub.status.busy": "2025-01-21T12:39:59.057834Z",
     "iopub.status.idle": "2025-01-21T12:39:59.073718Z",
     "shell.execute_reply": "2025-01-21T12:39:59.072959Z",
     "shell.execute_reply.started": "2025-01-21T12:39:59.058168Z"
    },
    "id": "xvUnYd3Bw2up",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create your wandb run\n",
    "run = wandb.init(\n",
    "    name    = \"more context with dropout in later layers w/o scheduling\",\n",
    "    project = \"hw1p2-CMU\",\n",
    "    config  = config,\n",
    "    # reinit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T12:40:01.140564Z",
     "iopub.status.busy": "2025-01-21T12:40:01.140209Z",
     "iopub.status.idle": "2025-01-21T12:40:01.148674Z",
     "shell.execute_reply": "2025-01-21T12:40:01.147938Z",
     "shell.execute_reply.started": "2025-01-21T12:40:01.140534Z"
    },
    "id": "wft15E_IxYFi",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/kaggle/working/wandb/run-20250121_123856-eckfd27r/files/model_arch.txt']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_arch  = str(model)\n",
    "\n",
    "arch_file   = open(\"model_arch.txt\", \"w\")\n",
    "file_write  = arch_file.write(model_arch)\n",
    "arch_file.close()\n",
    "\n",
    "wandb.save('model_arch.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nclx_04fu7Dd"
   },
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdLMWfEpyGOB"
   },
   "source": [
    "Finally, we run our abilations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T12:40:06.908746Z",
     "iopub.status.busy": "2025-01-21T12:40:06.908291Z",
     "iopub.status.idle": "2025-01-21T13:48:29.570296Z",
     "shell.execute_reply": "2025-01-21T13:48:29.569429Z",
     "shell.execute_reply.started": "2025-01-21T12:40:06.908710Z"
    },
    "id": "MG4F77Nm0Am9",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 69.0653%\tTrain Loss 1.0597\t Learning Rate 0.0010000\n",
      "\tVal Acc 72.5205%\tVal Loss 0.8842\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 73.2684%\tTrain Loss 0.9196\t Learning Rate 0.0010000\n",
      "\tVal Acc 73.4671%\tVal Loss 0.8526\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 74.3437%\tTrain Loss 0.8867\t Learning Rate 0.0010000\n",
      "\tVal Acc 74.2590%\tVal Loss 0.8348\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 74.9076%\tTrain Loss 0.8699\t Learning Rate 0.0010000\n",
      "\tVal Acc 74.6118%\tVal Loss 0.8269\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 75.3034%\tTrain Loss 0.8585\t Learning Rate 0.0010000\n",
      "\tVal Acc 74.9362%\tVal Loss 0.8221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Iterate over number of epochs to train and evaluate model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "\n",
    "    print(\"\\nEpoch {}/{}\".format(epoch+1, config['epochs']))\n",
    "\n",
    "    curr_lr                 = float(optimizer.param_groups[0]['lr'])\n",
    "    train_loss, train_acc   = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc       = eval(model, val_loader)\n",
    "\n",
    "    # Update the learning rate\n",
    "    # scheduler.step()\n",
    "\n",
    "    print(\"\\tTrain Acc {:.04f}%\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(train_acc*100, train_loss, curr_lr))\n",
    "    print(\"\\tVal Acc {:.04f}%\\tVal Loss {:.04f}\".format(val_acc*100, val_loss))\n",
    "\n",
    "    ### Log metrics at each epoch\n",
    "    wandb.log({'train_acc': train_acc*100, 'train_loss': train_loss,\n",
    "               'val_acc': val_acc*100, 'valid_loss': val_loss, 'lr': curr_lr})\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8695879,
     "sourceId": 80670,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

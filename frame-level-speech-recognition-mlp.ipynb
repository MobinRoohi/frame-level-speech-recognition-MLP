{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","vscode":{"interpreter":{"hash":"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":80670,"databundleVersionId":8695879,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Frame-Level Speech Recognition with Multilayer Perceptron","metadata":{"_uuid":"23c69f92-1d97-45c6-bf62-acb70b821d1f","_cell_guid":"7ba57a57-5d44-4134-8dbf-5e1b21ced51f","trusted":true,"collapsed":false,"id":"F9ERgBpbcMmB","jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"In this project, we will be working with MFCC data consisting of 28 features at each time step/frame. The model will be used to recognize the phoneme occured in that frame. After completion it will be submitted to the [\"11785 HW1P2 Fall 2024\" competition\"](https://www.kaggle.com/competitions/11785-hw1p2-f24/overview).\n\n\n\nThis project was completed according to the first homework in Carnegie Mellon University's CMU 11-785: Deep Learning course.","metadata":{"_uuid":"724ddbda-cf95-4f14-818d-740bd452d978","_cell_guid":"5fd25165-7eba-48d0-940e-91bba91de5d8","trusted":true,"collapsed":false,"id":"CLkH6GMGcWcE","jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"# Libraries","metadata":{"_uuid":"89f32fb0-b955-403e-8bc3-0695bfb030b3","_cell_guid":"8059b6b7-c92f-4bed-b2b6-c6b899f5ac39","trusted":true,"collapsed":false,"id":"z4vZbDmJvMp1","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"!pip install torchsummaryX==1.1.0 wandb --quiet","metadata":{"_uuid":"b8f6c124-d86a-4b11-ba3f-dce60c52b8ef","_cell_guid":"0e5506c9-a85e-445c-af12-8e5d660fda98","trusted":true,"collapsed":false,"id":"rwYu9sSUnSho","execution":{"iopub.status.busy":"2025-02-18T09:23:59.425404Z","iopub.execute_input":"2025-02-18T09:23:59.425621Z","iopub.status.idle":"2025-02-18T09:24:03.987734Z","shell.execute_reply.started":"2025-02-18T09:23:59.425600Z","shell.execute_reply":"2025-02-18T09:24:03.986607Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom torchsummaryX import summary\nimport sklearn\nimport gc\nimport zipfile\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport os\nimport datetime\nimport wandb\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(\"Device: \", device)","metadata":{"_uuid":"fafc556a-3e56-4a10-938f-0c3ded5b2413","_cell_guid":"e6ea2f6c-c66d-4844-9670-6e433e8d9379","trusted":true,"collapsed":false,"id":"qI4qfx7tiBZt","outputId":"ef79a3fc-5689-4e5a-d896-329b8a9d6a5c","execution":{"iopub.status.busy":"2025-02-18T09:24:03.988769Z","iopub.execute_input":"2025-02-18T09:24:03.989109Z","iopub.status.idle":"2025-02-18T09:24:09.912336Z","shell.execute_reply.started":"2025-02-18T09:24:03.989080Z","shell.execute_reply":"2025-02-18T09:24:09.911491Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Device:  cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"### PHONEME LIST\nPHONEMES = [\n            '[SIL]',   'AA',    'AE',    'AH',    'AO',    'AW',    'AY',\n            'B',     'CH',    'D',     'DH',    'EH',    'ER',    'EY',\n            'F',     'G',     'HH',    'IH',    'IY',    'JH',    'K',\n            'L',     'M',     'N',     'NG',    'OW',    'OY',    'P',\n            'R',     'S',     'SH',    'T',     'TH',    'UH',    'UW',\n            'V',     'W',     'Y',     'Z',     'ZH',    '[SOS]', '[EOS]']","metadata":{"_uuid":"20e9369a-bf96-4039-83c4-06b199f7bd00","_cell_guid":"b619a8e0-03a8-4445-91da-ccafe4e72c5b","trusted":true,"collapsed":false,"id":"N-9qE20hmCgQ","execution":{"iopub.status.busy":"2025-02-18T09:24:09.913231Z","iopub.execute_input":"2025-02-18T09:24:09.913575Z","iopub.status.idle":"2025-02-18T09:24:09.919427Z","shell.execute_reply.started":"2025-02-18T09:24:09.913546Z","shell.execute_reply":"2025-02-18T09:24:09.918653Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"wandb.login(key=\"a35a4beb5d7e2e112211e9cd7e103b10585e3132\")","metadata":{"_uuid":"277ea9c9-7181-4624-9d68-22b7dcafcc28","_cell_guid":"e859f55e-5263-45c5-98fa-a262e92d27e2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-18T09:24:09.920344Z","iopub.execute_input":"2025-02-18T09:24:09.920628Z","iopub.status.idle":"2025-02-18T09:24:16.598383Z","shell.execute_reply.started":"2025-02-18T09:24:09.920596Z","shell.execute_reply":"2025-02-18T09:24:16.597648Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmobin-roohi\u001b[0m (\u001b[33mmobin-roohi-university-of-tehran\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# Dataset Class","metadata":{"_uuid":"16b546a4-a0f5-4558-97e1-839185d68e35","_cell_guid":"2134b343-8b14-4d8e-9f8e-240f6615de44","trusted":true,"collapsed":false,"id":"Vuzce0_TdcaR","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Dataset class to load train and validation data\n\nclass AudioDataset(torch.utils.data.Dataset):\n\n    def __init__(self, root, phonemes = PHONEMES, context=0, partition= \"train-clean-100\"): \n        self.context = context\n        self.phonemes = phonemes\n\n        # MFCC directory\n        self.mfcc_dir = os.path.join(root, partition, 'mfcc')\n        \n        # Transcripts directory\n        self.transcript_dir = os.path.join(root, partition, 'transcript')\n\n        # List of MFCC and transcript files\n        mfcc_names = sorted(os.listdir(self.mfcc_dir))\n        transcript_names = sorted(os.listdir(self.transcript_dir))\n        assert len(mfcc_names) == len(transcript_names)\n\n        self.mfccs, self.transcripts = [], []\n\n        for i in range(len(mfcc_names)):\n            if i % 1000 == 0: \n                print(f\"Data {i} / {len(mfcc_names)}\")\n            # Load a single mfcc\n            mfcc = np.load(os.path.join(self.mfcc_dir, mfcc_names[i]))\n    \n            # Cepstral normalization\n            mfcc_norm = self.cepstral_normalization(mfcc)\n                    \n            # Load the corresponding transcript and removing [SOS] and [EOS]\n            transcript = np.load(os.path.join(self.transcript_dir, transcript_names[i]))[1:-1]\n            \n            # Save the preprocessed MFFCs and transcripts\n            self.mfccs.append(mfcc_norm)\n            self.transcripts.append(transcript)\n\n        # Concatenate all mfccs \n        self.mfccs = np.vstack(self.mfccs)\n\n        # Concatenate all transcripts \n        self.transcripts = np.concatenate(self.transcripts, axis=0)\n\n        # Length of the dataset is now the length of concatenated mfccs/transcripts\n        self.length = len(self.mfccs)\n\n        # We can introduce context by padding zeros on top and bottom of self.mfcc\n        zero_padding = np.zeros((self.context, 28))\n        self.mfccs = np.vstack([zero_padding, self.mfccs, zero_padding])\n\n        # Map transcripts to id integers using phonemes list\n        encoding_dict = {string : idx for idx, string in enumerate(phonemes)}\n        self.transcripts = np.array([encoding_dict[t] for t in self.transcripts])\n\n    def __len__(self):\n        return self.length\n\n    def __getitem__(self, ind):\n        # Frame with context frames to the left, and right\n        frames = self.mfccs[ind : ind + 2 * self.context + 1, :]\n        \n        # After slicing, the array has a of shape 2*context+1 x 28. But MLP requires 1d data and not 2d.\n        frames = frames.flatten()\n\n        # Convert to tensors\n        frames = torch.FloatTensor(frames)\n        phonemes = torch.tensor(self.transcripts[ind])\n\n        return frames, phonemes\n\n    def cepstral_normalization(self, mfcc):\n        # Mean and standard deviation\n        mean = np.mean(mfcc, axis = 0)\n        std = np.std(mfcc, axis = 0) + 1e-8\n\n        # Normalize\n        mfcc_norm = (mfcc - mean) / std\n\n        return mfcc_norm","metadata":{"_uuid":"6a038d90-d56a-4f3c-8ee9-9487cf15ad0e","_cell_guid":"cb81bf5f-6af4-4e8d-a635-a9a00db3a83d","trusted":true,"collapsed":false,"id":"YpLCvi3AJC5z","execution":{"iopub.status.busy":"2025-02-18T09:24:16.599197Z","iopub.execute_input":"2025-02-18T09:24:16.599638Z","iopub.status.idle":"2025-02-18T09:24:16.608788Z","shell.execute_reply.started":"2025-02-18T09:24:16.599615Z","shell.execute_reply":"2025-02-18T09:24:16.607922Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Dataset class to load test data (without transcripts)\n\nclass AudioTestDataset(torch.utils.data.Dataset):\n\n    def __init__(self, root, phonemes = PHONEMES, context=0, partition= \"test-clean\"): \n        self.context = context\n        self.phonemes = phonemes\n\n        # MFCC directory\n        self.mfcc_dir = os.path.join(root, partition, 'mfcc')\n\n        # List of MFCC files\n        mfcc_names = sorted(os.listdir(self.mfcc_dir))\n\n        self.mfccs = []\n\n        for i in range(len(mfcc_names)):\n            # Load a single mfcc\n            mfcc = np.load(os.path.join(self.mfcc_dir, mfcc_names[i]))\n    \n            # Cepstral normalization\n            mfcc_norm = self.cepstral_normalization(mfcc)\n            \n            # Save the preprocessed MFFCs\n            self.mfccs.append(mfcc_norm)\n\n        # Concatenate all mfccs \n        self.mfccs = np.vstack(self.mfccs)\n\n        # Length of the dataset is now the length of concatenated mfccs\n        self.length = len(self.mfccs)\n\n        # We can introduce context by padding zeros on top and bottom of self.mfcc\n        zero_padding = np.zeros((self.context, 28))\n        self.mfccs = np.vstack([zero_padding, self.mfccs, zero_padding])\n\n    def __len__(self):\n        return self.length\n\n    def __getitem__(self, ind):\n        # Frame with context frames to the left, and right\n        frames = self.mfccs[ind : ind + 2 * self.context + 1, :]\n        \n        # After slicing, the array has a of shape 2*context+1 x 28. But MLP requires 1d data and not 2d.\n        frames = frames.flatten()\n\n        # Convert to tensors\n        frames = torch.FloatTensor(frames)\n\n        return frames\n\n    def cepstral_normalization(self, mfcc):\n        # Mean and standard deviation\n        mean = np.mean(mfcc, axis = 0)\n        std = np.std(mfcc, axis = 0) + 1e-8\n\n        # Normalize\n        mfcc_norm = (mfcc - mean) / std\n\n        return mfcc_norm","metadata":{"_uuid":"ba1b5f57-9c8a-43e4-88a2-2339f9ecde16","_cell_guid":"63370683-70e4-418d-acd2-33b0050a9766","trusted":true,"collapsed":false,"id":"e8KfVP39S6o7","execution":{"iopub.status.busy":"2025-02-18T09:24:16.611305Z","iopub.execute_input":"2025-02-18T09:24:16.611506Z","iopub.status.idle":"2025-02-18T09:24:16.627807Z","shell.execute_reply.started":"2025-02-18T09:24:16.611488Z","shell.execute_reply":"2025-02-18T09:24:16.627144Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Parameters Configuration","metadata":{"_uuid":"67a409b3-0f7a-4529-bb99-6ad56f8b7665","_cell_guid":"1afe36e3-6412-4662-91d5-a2942250c9ea","trusted":true,"collapsed":false,"id":"qNacQ8bpt9nw","jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"We store the parameters and hyperparameters in a single configuration dictionary to make it easier to keep track of them during each experiment. It can also be used with weights and biases to log the parameters for each experiment and keep track of them across multiple experiments.","metadata":{"_uuid":"c87f7fbe-49cd-4149-9921-72f8f1d3bfc7","_cell_guid":"4229b038-f868-4b6e-8b2a-d0e25813d8ac","trusted":true,"collapsed":false,"id":"WE7tsinAuLNy","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"config = {\n    'epochs'        : 5,\n    'batch_size'    : 1024,\n    'context'       : 20,\n    'init_lr'       : 1e-3,\n    'architecture'  : 'initial-stage',\n    'gamma'         : 0.5\n    # Add more as needed - e.g dropout values, weight decay, scheduler parameters\n}","metadata":{"_uuid":"4be43af2-762e-4462-9eae-3f2cf2c0b945","_cell_guid":"402ac185-ac05-4ac2-acc5-3540482c5a67","trusted":true,"collapsed":false,"id":"PmKwlFqgt_Zq","execution":{"iopub.status.busy":"2025-02-18T09:24:16.629175Z","iopub.execute_input":"2025-02-18T09:24:16.629363Z","iopub.status.idle":"2025-02-18T09:24:16.645543Z","shell.execute_reply.started":"2025-02-18T09:24:16.629346Z","shell.execute_reply":"2025-02-18T09:24:16.644891Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Create Datasets","metadata":{"_uuid":"313539fd-b787-41aa-8fbf-689637545cd7","_cell_guid":"d95c8567-f1c0-420e-93f5-0fe1419131c5","trusted":true,"collapsed":false,"id":"2mlwaKlDt_2c","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Train/validation data\ntrain_data = AudioDataset(\"/kaggle/input/11785-hw1p2-f24/11785-f24-hw1p2\", phonemes = PHONEMES, context=config[\"context\"], partition=\"train-clean-100\")\nval_data = AudioDataset(\"/kaggle/input/11785-hw1p2-f24/11785-f24-hw1p2\", phonemes = PHONEMES, context=config[\"context\"], partition=\"dev-clean\")\n\n# Test data\ntest_data = AudioTestDataset(\"/kaggle/input/11785-hw1p2-f24/11785-f24-hw1p2\", phonemes = PHONEMES, context=config[\"context\"], partition=\"test-clean\")","metadata":{"_uuid":"c22f54d2-512b-483c-91c8-a3c6c0f534e8","_cell_guid":"c7955a54-3471-49b5-851b-75dcb6ff2ced","trusted":true,"collapsed":false,"id":"7xi7V8x8W9z4","execution":{"iopub.status.busy":"2025-02-18T09:24:16.646164Z","iopub.execute_input":"2025-02-18T09:24:16.646345Z","iopub.status.idle":"2025-02-18T09:34:54.000815Z","shell.execute_reply.started":"2025-02-18T09:24:16.646329Z","shell.execute_reply":"2025-02-18T09:34:53.999914Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Data 0 / 28539\nData 1000 / 28539\nData 2000 / 28539\nData 3000 / 28539\nData 4000 / 28539\nData 5000 / 28539\nData 6000 / 28539\nData 7000 / 28539\nData 8000 / 28539\nData 9000 / 28539\nData 10000 / 28539\nData 11000 / 28539\nData 12000 / 28539\nData 13000 / 28539\nData 14000 / 28539\nData 15000 / 28539\nData 16000 / 28539\nData 17000 / 28539\nData 18000 / 28539\nData 19000 / 28539\nData 20000 / 28539\nData 21000 / 28539\nData 22000 / 28539\nData 23000 / 28539\nData 24000 / 28539\nData 25000 / 28539\nData 26000 / 28539\nData 27000 / 28539\nData 28000 / 28539\nData 0 / 2703\nData 1000 / 2703\nData 2000 / 2703\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Dataloaders for train, val and test datasets\n\n\ntrain_loader = torch.utils.data.DataLoader(\n    dataset     = train_data,\n    num_workers = 4,\n    batch_size  = config['batch_size'],\n    pin_memory  = True,\n    shuffle     = True\n)\n\nval_loader = torch.utils.data.DataLoader(\n    dataset     = val_data,\n    num_workers = 2,\n    batch_size  = config['batch_size'],\n    pin_memory  = True,\n    shuffle     = False\n)\n\ntest_loader = torch.utils.data.DataLoader(\n    dataset     = test_data,\n    num_workers = 2,\n    batch_size  = config['batch_size'],\n    pin_memory  = True,\n    shuffle     = False\n)\n\n\nprint(\"Batch size     : \", config['batch_size'])\nprint(\"Context        : \", config['context'])\nprint(\"Input size     : \", (2*config['context']+1)*28)\nprint(\"Output symbols : \", len(PHONEMES))\n\nprint(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\nprint(\"Validation dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\nprint(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))","metadata":{"_uuid":"4c66bb2b-265d-4d6e-bfae-66f9c77a6bde","_cell_guid":"0f85701b-e291-405b-9b7c-0169d97ae8ec","trusted":true,"collapsed":false,"id":"4mzoYfTKu14s","execution":{"iopub.status.busy":"2025-02-18T09:34:54.001759Z","iopub.execute_input":"2025-02-18T09:34:54.002031Z","iopub.status.idle":"2025-02-18T09:34:54.010706Z","shell.execute_reply.started":"2025-02-18T09:34:54.002003Z","shell.execute_reply":"2025-02-18T09:34:54.010026Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Batch size     :  1024\nContext        :  20\nInput size     :  1148\nOutput symbols :  42\nTrain dataset samples = 36091157, batches = 35246\nValidation dataset samples = 1928204, batches = 1884\nTest dataset samples = 1934138, batches = 1889\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Testing code to check if the data loaders are working\nfor i, data in enumerate(train_loader):\n    frames, phoneme = data\n    print(frames.shape, phoneme.shape)\n    break","metadata":{"_uuid":"8c1f4dc5-783c-4076-b46e-f3b4c6a83b18","_cell_guid":"5284ac22-9f34-4923-8349-8ad769260fa0","trusted":true,"collapsed":false,"id":"n-GV3UvgLSoF","execution":{"iopub.status.busy":"2025-02-18T09:34:54.011488Z","iopub.execute_input":"2025-02-18T09:34:54.011797Z","iopub.status.idle":"2025-02-18T09:34:59.602411Z","shell.execute_reply.started":"2025-02-18T09:34:54.011766Z","shell.execute_reply":"2025-02-18T09:34:59.601579Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"torch.Size([1024, 1148]) torch.Size([1024])\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Network Architecture","metadata":{"_uuid":"938005dd-381f-41bb-9526-4d8432b47882","_cell_guid":"7effc338-4073-4be6-8b15-7d376e3b0070","trusted":true,"collapsed":false,"id":"Nxjwve20JRJ2","jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"This section defines the network architecture for the homework.","metadata":{"_uuid":"1de43fa5-91f4-4409-a638-c2b3223bd97d","_cell_guid":"833a47ef-610b-4216-b085-84f68fa5f039","trusted":true,"collapsed":false,"id":"3NJzT-mRw6iy","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"class PerceptronLayer(torch.nn.Module):\n    \n    def __init__(self, c_in, c_out, dropout=0.5):\n        super(PerceptronLayer, self).__init__()\n        self.layer = torch.nn.Sequential(torch.nn.Linear(in_features=c_in, out_features=c_out),\n                                   torch.nn.BatchNorm1d(c_out), torch.nn.Dropout(dropout), torch.nn.ReLU())\n\n    def forward(self, x):\n        return self.layer(x)\n\nclass Network(torch.nn.Module):\n\n    def __init__(self, input_size, dropout=0.5):\n        super().__init__()\n        self.layer1 = PerceptronLayer(input_size, 2048, dropout)\n        self.layer2 = PerceptronLayer(2048, 2048, dropout)\n        self.layer3 = PerceptronLayer(2048, 2048, dropout)\n        self.layer4 = PerceptronLayer(2048, 2048, dropout)\n        self.layer5 = PerceptronLayer(2048, 2048, dropout)\n        self.layer6 = torch.nn.Linear(2048, 71)\n    \n    def forward(self, x):\n        x1 = self.layer1(x)\n        x3 = self.layer3(x1 + self.layer2(x1))\n        x5 = self.layer5(x3 + self.layer4(x3))\n        return self.layer6(x5)","metadata":{"_uuid":"ef1fc4fb-b993-44ab-857f-1e7cb95905ff","_cell_guid":"d1fb869b-1383-4409-8ec3-e051a169a8b9","trusted":true,"collapsed":false,"id":"OvcpontXQq9j","execution":{"iopub.status.busy":"2025-02-18T09:34:59.603405Z","iopub.execute_input":"2025-02-18T09:34:59.603708Z","iopub.status.idle":"2025-02-18T09:34:59.610477Z","shell.execute_reply.started":"2025-02-18T09:34:59.603681Z","shell.execute_reply":"2025-02-18T09:34:59.609641Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Define Model, Loss Function and Optimizer","metadata":{"_uuid":"843a34d1-0c5c-4372-a48d-27a6b6ae7434","_cell_guid":"39a4a366-6f71-4cb2-88ec-455a57e6ecf2","trusted":true,"collapsed":false,"id":"HejoSXe3vMVU","jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"Here we define the model, loss function, optimizer and optionally a learning rate scheduler.","metadata":{"_uuid":"d0f5fac3-0900-4802-b632-96ad2948ed38","_cell_guid":"87169c32-7b6d-458d-bb5e-945e0b626307","trusted":true,"collapsed":false,"id":"xAhGBH7-xxth","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"INPUT_SIZE  = (2*config['context'] + 1) * 28 \nmodel       = Network(INPUT_SIZE).to(device)\nsummary(model, frames.to(device))","metadata":{"_uuid":"f4d12340-2383-4552-a34b-dac947d07956","_cell_guid":"8339f0b1-8c19-4544-9ab3-e40b30620733","trusted":true,"collapsed":false,"id":"_qtrEM1ZvLje","execution":{"iopub.status.busy":"2025-02-18T09:34:59.611188Z","iopub.execute_input":"2025-02-18T09:34:59.611468Z","iopub.status.idle":"2025-02-18T09:34:59.995473Z","shell.execute_reply.started":"2025-02-18T09:34:59.611443Z","shell.execute_reply":"2025-02-18T09:34:59.994778Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------------------------------------------\nLayer                   Kernel Shape         Output Shape         # Params (K)      # Mult-Adds (M)\n====================================================================================================\n0_Linear                [1148, 2048]         [1024, 2048]             2,353.15                 2.35\n1_BatchNorm1d                 [2048]         [1024, 2048]                 4.10                 0.00\n2_Dropout                          -         [1024, 2048]                    -                    -\n3_ReLU                             -         [1024, 2048]                    -                    -\n4_Linear                [2048, 2048]         [1024, 2048]             4,196.35                 4.19\n5_BatchNorm1d                 [2048]         [1024, 2048]                 4.10                 0.00\n6_Dropout                          -         [1024, 2048]                    -                    -\n7_ReLU                             -         [1024, 2048]                    -                    -\n8_Linear                [2048, 2048]         [1024, 2048]             4,196.35                 4.19\n9_BatchNorm1d                 [2048]         [1024, 2048]                 4.10                 0.00\n10_Dropout                         -         [1024, 2048]                    -                    -\n11_ReLU                            -         [1024, 2048]                    -                    -\n12_Linear               [2048, 2048]         [1024, 2048]             4,196.35                 4.19\n13_BatchNorm1d                [2048]         [1024, 2048]                 4.10                 0.00\n14_Dropout                         -         [1024, 2048]                    -                    -\n15_ReLU                            -         [1024, 2048]                    -                    -\n16_Linear               [2048, 2048]         [1024, 2048]             4,196.35                 4.19\n17_BatchNorm1d                [2048]         [1024, 2048]                 4.10                 0.00\n18_Dropout                         -         [1024, 2048]                    -                    -\n19_ReLU                            -         [1024, 2048]                    -                    -\n20_Linear                 [2048, 71]           [1024, 71]               145.48                 0.15\n====================================================================================================\n# Params:    19,304.52K\n# Mult-Adds: 19.28M\n----------------------------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Defining Loss function.\ncriterion = torch.nn.CrossEntropyLoss() \n\n# Defining Optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr= config['init_lr']) \n\n# Defining Scheduler for Learning Rate\nscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = config['gamma'])\n\n# # Later: Mixed Precision Training\n# !nvidia-smi","metadata":{"_uuid":"cc24a2f3-d5cf-46af-a636-2682309c8ba8","_cell_guid":"51826f2f-7173-48c2-8bcb-26588b4faeef","trusted":true,"collapsed":false,"id":"UROGEVJevKD-","execution":{"iopub.status.busy":"2025-02-18T09:34:59.996238Z","iopub.execute_input":"2025-02-18T09:34:59.996536Z","iopub.status.idle":"2025-02-18T09:35:01.844024Z","shell.execute_reply.started":"2025-02-18T09:34:59.996512Z","shell.execute_reply":"2025-02-18T09:35:01.843142Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Training and Validation Functions","metadata":{"_uuid":"67330ba5-a40b-4c3e-ac78-acd322fd6579","_cell_guid":"02afdca7-3763-487c-8ed0-ce824af34069","trusted":true,"collapsed":false,"id":"IBwunYpyugFg","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()","metadata":{"_uuid":"495c5181-66ab-429b-8d3e-08b0ae9ee774","_cell_guid":"ac3f09ed-cb8a-410b-ba33-9bbf0d69cf92","trusted":true,"collapsed":false,"id":"XblOHEVtKab2","execution":{"iopub.status.busy":"2025-02-18T09:35:01.844950Z","iopub.execute_input":"2025-02-18T09:35:01.845719Z","iopub.status.idle":"2025-02-18T09:35:02.053928Z","shell.execute_reply.started":"2025-02-18T09:35:01.845685Z","shell.execute_reply":"2025-02-18T09:35:02.053185Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"855"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"from torch.amp import autocast, GradScaler\nfrom tqdm import tqdm\n\ndef train(model, dataloader, optimizer, criterion, update_interval=100):\n    model.train()\n    tloss, tacc = 0, 0  # Monitoring loss and accuracy\n    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n\n    # Create a GradScaler once at the beginning of training.\n    scaler = GradScaler()\n\n    for i, (frames, phonemes) in enumerate(dataloader):\n        ### Initialize Gradients\n        optimizer.zero_grad()\n\n        ### Move Data to Device (Ideally GPU)\n        frames = frames.to(device)\n        phonemes = phonemes.to(device)\n\n        ### Forward Propagation\n        ### Runs the forward pass with autocasting.\n        with autocast(device_type=device, dtype=torch.float16):\n            logits = model(frames)\n\n            ### Loss Calculation\n            loss = criterion(logits, phonemes)\n\n        ### Backward Propagation\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        tloss += loss.item()\n        tacc += torch.sum(torch.argmax(logits, dim=1) == phonemes).item() / logits.shape[0]\n\n        # Update progress bar less frequently\n        if (i + 1) % update_interval == 0 or (i + 1) == len(dataloader):\n            batch_bar.set_postfix(\n                loss=\"{:.04f}\".format(float(tloss / (i + 1))),\n                acc=\"{:.04f}%\".format(float(tacc * 100 / (i + 1)))\n            )\n            batch_bar.update(update_interval)\n\n        ### Release memory\n        del frames, phonemes, logits\n        torch.cuda.empty_cache()\n    \n    batch_bar.close()\n    tloss /= len(dataloader)\n    tacc /= len(dataloader)\n\n    return tloss, tacc","metadata":{"_uuid":"a7280658-8956-417e-8e69-3d2981644156","_cell_guid":"66512644-e1d9-4dd4-b2b4-6b3153ee9ca4","trusted":true,"collapsed":false,"id":"8wjPz7DHqKcL","execution":{"iopub.status.busy":"2025-02-18T09:35:02.054783Z","iopub.execute_input":"2025-02-18T09:35:02.055052Z","iopub.status.idle":"2025-02-18T09:35:02.062038Z","shell.execute_reply.started":"2025-02-18T09:35:02.055030Z","shell.execute_reply":"2025-02-18T09:35:02.061218Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def eval(model, dataloader, update_interval=100):\n\n    model.eval() # set model in evaluation mode\n    vloss, vacc = 0, 0 # Monitoring loss and accuracy\n    batch_bar   = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n\n    for i, (frames, phonemes) in enumerate(dataloader):\n\n        ### Move data to device (ideally GPU)\n        frames      = frames.to(device)\n        phonemes    = phonemes.to(device)\n\n        # makes sure that there are no gradients computed as we are not training the model now\n        with torch.inference_mode():\n            ### Forward Propagation\n            logits  = model(frames)\n            ### Loss Calculation\n            loss    = criterion(logits, phonemes)\n\n        vloss   += loss.item()\n        vacc    += torch.sum(torch.argmax(logits, dim= 1) == phonemes).item()/logits.shape[0]\n\n        # Update progress bar less frequently\n        if (i + 1) % update_interval == 0 or (i + 1) == len(dataloader):\n            batch_bar.set_postfix(\n                loss=\"{:.04f}\".format(float(vloss / (i + 1))),\n                acc=\"{:.04f}%\".format(float(vacc * 100 / (i + 1)))\n            )\n            batch_bar.update(update_interval)\n\n        ### Release memory\n        del frames, phonemes, logits\n        torch.cuda.empty_cache()\n\n    batch_bar.close()\n    vloss   /= len(val_loader)\n    vacc    /= len(val_loader)\n\n    return vloss, vacc","metadata":{"_uuid":"f8fba21e-33a4-460f-8b82-0a6ed674b733","_cell_guid":"da28d18c-b7e0-41c8-9456-2e33d32dc7b9","trusted":true,"collapsed":false,"id":"Q5npQNFH315V","execution":{"iopub.status.busy":"2025-02-18T09:35:02.062987Z","iopub.execute_input":"2025-02-18T09:35:02.063295Z","iopub.status.idle":"2025-02-18T09:35:02.080818Z","shell.execute_reply.started":"2025-02-18T09:35:02.063263Z","shell.execute_reply":"2025-02-18T09:35:02.080066Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Weights and Biases Setup","metadata":{"_uuid":"8a028fb6-ab6b-4589-907f-d762b251edfb","_cell_guid":"62c3ee58-4831-4e60-a95a-1a9ec5a8b037","trusted":true,"collapsed":false,"id":"yMd_XxPku5qp","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Create your wandb run\nrun = wandb.init(\n    name    = \"fourth run (skip model)\",\n    project = \"hw1p2\",\n    config  = config \n)","metadata":{"_uuid":"2a92e10d-2f30-48d8-aa47-78210213fdb4","_cell_guid":"980eb527-cd1b-4e7e-9b7d-969ceaea5691","trusted":true,"collapsed":false,"id":"xvUnYd3Bw2up","execution":{"iopub.status.busy":"2025-02-18T09:35:02.081505Z","iopub.execute_input":"2025-02-18T09:35:02.081711Z","iopub.status.idle":"2025-02-18T09:35:08.367496Z","shell.execute_reply.started":"2025-02-18T09:35:02.081693Z","shell.execute_reply":"2025-02-18T09:35:08.366626Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250218_093502-j07lyru3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/mobin-roohi-university-of-tehran/hw1p2/runs/j07lyru3' target=\"_blank\">fourth run (skip model)</a></strong> to <a href='https://wandb.ai/mobin-roohi-university-of-tehran/hw1p2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/mobin-roohi-university-of-tehran/hw1p2' target=\"_blank\">https://wandb.ai/mobin-roohi-university-of-tehran/hw1p2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/mobin-roohi-university-of-tehran/hw1p2/runs/j07lyru3' target=\"_blank\">https://wandb.ai/mobin-roohi-university-of-tehran/hw1p2/runs/j07lyru3</a>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"model_arch  = str(model)\n\narch_file   = open(\"model_arch.txt\", \"w\")\nfile_write  = arch_file.write(model_arch)\narch_file.close()\n\nwandb.save('model_arch.txt')","metadata":{"_uuid":"cda0c41e-c529-4c05-b763-c3f65d5d8e2f","_cell_guid":"149459e5-6ccd-4dfe-aeb6-42f150272899","trusted":true,"collapsed":false,"id":"wft15E_IxYFi","execution":{"iopub.status.busy":"2025-02-18T09:35:08.368406Z","iopub.execute_input":"2025-02-18T09:35:08.368698Z","iopub.status.idle":"2025-02-18T09:35:08.376361Z","shell.execute_reply.started":"2025-02-18T09:35:08.368673Z","shell.execute_reply":"2025-02-18T09:35:08.375478Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/wandb/run-20250218_093502-j07lyru3/files/model_arch.txt']"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"# Experiment","metadata":{"_uuid":"1423b5f1-57bc-4b27-b5c8-0169a942c8de","_cell_guid":"a194e267-3715-40c1-937c-0cbcac0a356d","trusted":true,"collapsed":false,"id":"nclx_04fu7Dd","jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"Finally, we run our abilations!","metadata":{"_uuid":"b3e13d2c-426d-4dcb-bff5-b0a5eee753a9","_cell_guid":"69e30f8b-573b-4aa7-aa05-e0720be7f331","trusted":true,"collapsed":false,"id":"MdLMWfEpyGOB","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Iterate over number of epochs to train and evaluate model\ntorch.cuda.empty_cache()\ngc.collect()\nwandb.watch(model, log=\"all\")\n\nfor epoch in range(config['epochs']):\n\n    print(\"\\nEpoch {}/{}\".format(epoch+1, config['epochs']))\n\n    curr_lr                 = float(optimizer.param_groups[0]['lr'])\n    train_loss, train_acc   = train(model, train_loader, optimizer, criterion)\n    val_loss, val_acc       = eval(model, val_loader)\n\n    # Update the learning rate\n    scheduler.step()\n\n    print(\"\\tTrain Acc {:.04f}%\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(train_acc*100, train_loss, curr_lr))\n    print(\"\\tVal Acc {:.04f}%\\tVal Loss {:.04f}\".format(val_acc*100, val_loss))\n\n    ### Log metrics at each epoch\n    wandb.log({'train_acc': train_acc*100, 'train_loss': train_loss,\n               'val_acc': val_acc*100, 'valid_loss': val_loss, 'lr': curr_lr})","metadata":{"_uuid":"bf1139a3-a8a2-4931-9970-c5e5c370239b","_cell_guid":"a1ec0113-422c-4f1e-8b37-1b7de628c77c","trusted":true,"collapsed":false,"id":"MG4F77Nm0Am9","execution":{"iopub.status.busy":"2025-02-18T09:35:08.377367Z","iopub.execute_input":"2025-02-18T09:35:08.377620Z","iopub.status.idle":"2025-02-18T11:00:13.478212Z","shell.execute_reply.started":"2025-02-18T09:35:08.377598Z","shell.execute_reply":"2025-02-18T11:00:13.477183Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                       \r","output_type":"stream"},{"name":"stdout","text":"\tTrain Acc 75.2363%\tTrain Loss 0.7617\t Learning Rate 0.0005000\n\tVal Acc 79.3344%\tVal Loss 0.6170\n\nEpoch 3/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                       \r","output_type":"stream"},{"name":"stdout","text":"\tTrain Acc 76.6151%\tTrain Loss 0.7151\t Learning Rate 0.0002500\n\tVal Acc 80.1539%\tVal Loss 0.5921\n\nEpoch 4/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                       \r","output_type":"stream"},{"name":"stdout","text":"\tTrain Acc 77.2737%\tTrain Loss 0.6931\t Learning Rate 0.0001250\n\tVal Acc 80.5290%\tVal Loss 0.5806\n\nEpoch 5/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                   818]","output_type":"stream"},{"name":"stdout","text":"\tTrain Acc 77.6138%\tTrain Loss 0.6818\t Learning Rate 0.0000625\n\tVal Acc 80.6793%\tVal Loss 0.5748\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":19}]}